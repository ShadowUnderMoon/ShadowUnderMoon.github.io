<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>All Posts - 爱吃芒果</title>
        <link>http://example.org/posts/</link>
        <description>All Posts | 爱吃芒果</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><lastBuildDate>Sat, 07 Jun 2025 19:05:49 &#43;0800</lastBuildDate><atom:link href="http://example.org/posts/" rel="self" type="application/rss+xml" /><item>
    <title>Spark错误容忍机制</title>
    <link>http://example.org/posts/spark_fault_tolerance/</link>
    <pubDate>Sat, 07 Jun 2025 19:05:49 &#43;0800</pubDate>
    <author>爱吃芒果</author>
    <guid>http://example.org/posts/spark_fault_tolerance/</guid>
    <description><![CDATA[<p>Spark的错误容忍机制的核心方法主要有两种：</p>
<ol>
<li>通过重新执行计算任务来容忍错误，当job抛出异常不能继续执行时，重新启动计算任务，再次执行</li>
<li>通过采用checkpoint机制，对一些重要的输入、输出、中间数据进行持久化，这可以在一定程度上解决数据丢失问题，而且能够提高任务重新计算时的效率。</li>
</ol>
<p>Spark采用了延迟删除策略，将上游stage的Shuffle Write的结果写入本地磁盘，只有在当前job完成后，才删除Shuffle Writre写入磁盘的数据。这样，即使stage2中某个task执行失败，但由于上游的stage0和stage1的输出数据还在磁盘上，也可以再次通过Shuffle Read读取得到相同的数据，避免再次执行上游stage中的task，所以，Spark根据ShuffleDependency切分出的stage既保证了task的独立性，也方便了错误容忍的重新计算。</p>]]></description>
</item>
<item>
    <title>Spark数据缓存</title>
    <link>http://example.org/posts/spark_data_cache/</link>
    <pubDate>Sat, 07 Jun 2025 16:14:21 &#43;0800</pubDate>
    <author>爱吃芒果</author>
    <guid>http://example.org/posts/spark_data_cache/</guid>
    <description><![CDATA[<p>缓存机制实际上是一种空间换时间的方法，集体的，如果数据满足一下3条，就可以进行缓存.</p>
<ol>
<li>会被重复使用的数据。更确切地，会被多个job共享使用的数据。被共享使用的次数越多，那么缓存该数据的性价比越高。一般来说，对于迭代型和交互型应用非常适合。</li>
<li>数据不宜过大。过大会占用大量的存储空间，导致内存不足，也会降低数据计算时可使用的空间。虽然缓存数据过大时也可以存放到磁盘，但磁盘的I/O代价比较高，有时甚至不如重新计算块。</li>
<li>非重复缓存的数据。重复缓存的意思是如果缓存了某个RDD，那么该RDD通过OneToOneDependency连接的parent RDD就不需要被缓存了，除非有job不使用缓存的RDD，而直接使用parent RDD。</li>
</ol>
<p>包含数据缓存操作的应用执行流程生成的规则：Spark首先假设应用没有数据缓存，正常生成逻辑处理流程（RDD之间的数据依赖关系），然后从第2个job开始，将cached RDD 之前的RDD都去掉，得到削减后的逻辑处理流程。最后，将逻辑处理流程转化为物理执行计划。</p>]]></description>
</item>
<item>
    <title>Spark Job执行流程</title>
    <link>http://example.org/posts/spark_job_execution/</link>
    <pubDate>Sat, 07 Jun 2025 10:16:21 &#43;0800</pubDate>
    <author>爱吃芒果</author>
    <guid>http://example.org/posts/spark_job_execution/</guid>
    <description><![CDATA[<div class="code-block code-line-numbers open" style="counter-reset: code-block 0">
    <div class="code-header language-java">
        <span class="code-title"><i class="arrow fas fa-angle-right fa-fw" aria-hidden="true"></i></span>
        <span class="ellipses"><i class="fas fa-ellipsis-h fa-fw" aria-hidden="true"></i></span>
        <span class="copy" title="Copy to clipboard"><i class="far fa-copy fa-fw" aria-hidden="true"></i></span>
    </div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-java" data-lang="java"><span class="line"><span class="cl"><span class="c1">// CoarseGrainedExecutorBackend</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="k">case</span><span class="w"> </span><span class="n">LaunchTask</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="w"> </span><span class="o">=&gt;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">executor</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="kc">null</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="n">exitExecutor</span><span class="p">(</span><span class="n">1</span><span class="p">,</span><span class="w"> </span><span class="s">&#34;Received LaunchTask command but executor was null&#34;</span><span class="p">)</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="n">val</span><span class="w"> </span><span class="n">taskDesc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">TaskDescription</span><span class="p">.</span><span class="na">decode</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="na">value</span><span class="p">)</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="n">logInfo</span><span class="p">(</span><span class="n">log</span><span class="s">&#34;Got assigned task ${MDC(LogKeys.TASK_ID, taskDesc.taskId)}&#34;</span><span class="p">)</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="n">executor</span><span class="p">.</span><span class="na">launchTask</span><span class="p">(</span><span class="k">this</span><span class="p">,</span><span class="w"> </span><span class="n">taskDesc</span><span class="p">)</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="p">}</span></span></span></code></pre></div></div>
<p>接收到Drive端传来的task，反序列化后，启动task</p>]]></description>
</item>
<item>
    <title>Spark Shuffle机制</title>
    <link>http://example.org/posts/shuffle/</link>
    <pubDate>Sun, 01 Jun 2025 09:18:40 &#43;0800</pubDate>
    <author>爱吃芒果</author>
    <guid>http://example.org/posts/shuffle/</guid>
    <description><![CDATA[<p>运行在不同stage、不同节点上的task见通过shuffle机制传递数据，shuffle解决的问题是如何将数据进行重新组织，使其能够在上游和下游task之间进行传递和计算。如果只是单纯的数据传递，则只需要将数据进行分区、通过网络传输即可，没有太大的难度，但shuffle机制还需要进行各种类型的计算（如聚合、排序），而且数据量一般会很大，如果支持这些不同类型的计算，如果提高shuffle的性能都是shuffle机制设计的难点。</p>]]></description>
</item>
<item>
    <title>Java ConcurrentHashMap</title>
    <link>http://example.org/posts/java-concurrenthashmap/</link>
    <pubDate>Wed, 28 May 2025 16:46:29 &#43;0800</pubDate>
    <author>爱吃芒果</author>
    <guid>http://example.org/posts/java-concurrenthashmap/</guid>
    <description><![CDATA[<p>这篇是对<a href="https://www.javadoop.com/post/hashmap" target="_blank" rel="noopener noreffer ">javadoop</a>对concurrentHashMap非常棒的源码解析的学习。</p>
<h2 id="java7-hashmap">Java7 HashMap</h2>
<p>HashMap是一个非并发安全的hashmap，使用链表数组实现，逻辑比较简单。</p>]]></description>
</item>
<item>
    <title>Spark物理执行计划</title>
    <link>http://example.org/posts/spark_physical_plan/</link>
    <pubDate>Sun, 25 May 2025 11:16:21 &#43;0800</pubDate>
    <author>爱吃芒果</author>
    <guid>http://example.org/posts/spark_physical_plan/</guid>
    <description><![CDATA[<h2 id="spark物理执行计划生成方法">Spark物理执行计划生成方法</h2>
<p>Spark具体采用3个步骤来生成物理执行计划，首先根据action操作顺序将应用划分为作业（job），然后根据每个job的逻辑处理流程中的ShuffleDependency依赖关系，将job划分为执行阶段（stage）。最后在每个stage中，根据最后生成的RDD的分区个数生成多个计算任务（task）。</p>]]></description>
</item>
<item>
    <title>Grpc Metric</title>
    <link>http://example.org/posts/grpc-metric/</link>
    <pubDate>Tue, 13 May 2025 22:33:46 &#43;0800</pubDate>
    <author>爱吃芒果</author>
    <guid>http://example.org/posts/grpc-metric/</guid>
    <description><![CDATA[<h2 id="opentelemetry">OpenTelemetry</h2>
<p>OpenTelemetry是CNCF孵化的开源观测框架，用于创建和管理遥测数据（telemetry），比如metrics, tracing, logs。这一项目的核心目标是避免依赖于vendor，从而可以更好地集成和拓展。</p>]]></description>
</item>
<item>
    <title>Spark逻辑处理流程</title>
    <link>http://example.org/posts/spark_logical_plan/</link>
    <pubDate>Sun, 11 May 2025 15:20:27 &#43;0800</pubDate>
    <author>爱吃芒果</author>
    <guid>http://example.org/posts/spark_logical_plan/</guid>
    <description><![CDATA[<p>Spark应用程序需要先转化为逻辑处理流程，逻辑处理流程主要包括：</p>
<ul>
<li>RDD数据模型</li>
<li>数据操作</li>
<li>数据依赖关系</li>
</ul>
<p>数据操作分为两种，<code>transformation</code>操作并不会触发job的实际执行，<code>action</code>操作创建job并立即执行。类似于java中的stream，采用懒加载的方式。</p>]]></description>
</item>
<item>
    <title>Spark基础知识</title>
    <link>http://example.org/posts/spark-base/</link>
    <pubDate>Sat, 10 May 2025 11:51:10 &#43;0800</pubDate>
    <author>爱吃芒果</author>
    <guid>http://example.org/posts/spark-base/</guid>
    <description><![CDATA[<h2 id="rdd数据模型">RDD数据模型</h2>
<p>RDD （Resilient Distributed DataSet)是spark对计算过程中输入输出数据以及中间数据的抽象，表示不可变、分区的集合数据，可以被并行处理。</p>]]></description>
</item>
<item>
    <title>Grpc源码分析</title>
    <link>http://example.org/posts/grpc-in-practice/</link>
    <pubDate>Fri, 02 May 2025 13:26:57 &#43;0800</pubDate>
    <author>爱吃芒果</author>
    <guid>http://example.org/posts/grpc-in-practice/</guid>
    <description><![CDATA[<h2 id="gprc流程概括">gprc流程概括</h2>
<p></p>
<p>grpc的流程可以大致分成两个阶段，分别为grpc连接阶段和grpc交互阶段，如图所示（此图来自后面的参考文献）。</p>
<p>在RPC连接阶段，client和server之间建立起TCP连接，grpc底层依赖于HTTP2，因此client和server还需要协调frame的相关设置，例如frame的大小，滑动窗口的大小等。</p>]]></description>
</item>
</channel>
</rss>
